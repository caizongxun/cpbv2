#!/usr/bin/env python3\n\"\"\"\nColab/Kaggle Quick Start - V4 GPU Fix\nCopy and run this entire cell in your notebook\n\"\"\"\n\nimport subprocess\nimport sys\n\n# Step 1: Download diagnostic tool\nprint(\"Downloading GPU diagnostic tool...\")\nsubprocess.run([\n    sys.executable, '-m', 'pip', 'install', '-q', 'requests'\n], check=True)\n\nimport requests\ndiag_code = requests.get(\n    'https://raw.githubusercontent.com/caizongxun/cpbv2/main/v4_gpu_diagnostic.py'\n).text\n\nprint(\"\\nRunning GPU diagnostics...\\n\")\nexec(diag_code)\n\n# Step 2: Display quick fixes\nprint(\"\\n\" + \"=\"*70)\nprint(\"QUICK FIX CHECKLIST FOR YOUR TRAINING CODE\")\nprint(\"=\"*70)\n\nfixes = [\n    (\"1\", \"Pre-transfer all data to GPU (avoid loop transfers)\", \n     \"X_gpu = X.to(device, non_blocking=True).contiguous()\"),\n    (\"2\", \"Add torch.cuda.synchronize() after forward/backward\", \n     \"torch.cuda.synchronize()\"),\n    (\"3\", \"Check Seq2SeqLSTMGPUv2 has no CPU operations\", \n     \"Check: no .item(), if conditions with CPU tensors\"),\n    (\"4\", \"Use only GPU tensor indexing in training loop\", \n     \"X_b = X_gpu[i:end].contiguous()  # From GPU tensor\"),\n    (\"5\", \"Create model directly on GPU\", \n     \"model = Model(..., device=device)\"),\n]\n\nfor num, desc, code in fixes:\n    print(f\"\\n{num}. {desc}\")\n    print(f\"   Code: {code}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"After making these fixes:\")\nprint(\"1. Re-run this diagnostic\")\nprint(\"2. Expected GPU memory usage: 2-5GB (not <100MB)\")\nprint(\"3. Expected GPU utilization: 50-80% (not ~0%)\")\nprint(\"=\"*70)\n"