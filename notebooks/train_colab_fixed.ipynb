{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPB v2: LSTM Cryptocurrency Price Prediction Training\n",
    "\n",
    "Complete training pipeline for 20+ coins, multi-timeframe (15m, 1h) models on Google Colab.\n",
    "\n",
    "**Fixed Version**: Proper path handling for Colab environment\n",
    "**Target Time**: < 2 hours\n",
    "**Hardware**: Colab Free GPU (T4)\n",
    "**Output**: Models uploaded to Hugging Face automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 0: Setup and Dependencies (Run this first!)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Print Colab info\n",
    "print('=== Colab Environment ===' )\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Working Dir: {os.getcwd()}')\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f'GPU Available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU Name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Clone Repository\n",
    "# ============================================================================\n",
    "\n",
    "# Clone the repo\n",
    "!rm -rf /tmp/cpbv2  # Remove old copy if exists\n",
    "!git clone https://github.com/caizongxun/cpbv2.git /tmp/cpbv2\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir('/tmp/cpbv2')\n",
    "print(f'Changed to: {os.getcwd()}')\n",
    "\n",
    "# List files\n",
    "print('\\nRepository structure:')\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Install Dependencies\n",
    "# ============================================================================\n",
    "\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q pandas numpy scikit-learn\n",
    "!pip install -q requests python-dotenv\n",
    "!pip install -q ta-lib pandas-ta\n",
    "!pip install -q huggingface-hub\n",
    "!pip install -q tqdm matplotlib seaborn\n",
    "\n",
    "print('All dependencies installed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Add to Python Path\n",
    "# ============================================================================\n",
    "\n",
    "# FIX: Add current directory to Python path\n",
    "repo_path = '/tmp/cpbv2'\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n",
    "print(f'Added to sys.path: {repo_path}')\n",
    "print(f'sys.path[0]: {sys.path[0]}')\n",
    "\n",
    "# Verify imports work\n",
    "import importlib\n",
    "import os.path\n",
    "\n",
    "src_path = os.path.join(repo_path, 'src')\n",
    "print(f'\\nChecking src directory: {src_path}')\n",
    "print(f'src exists: {os.path.exists(src_path)}')\n",
    "print(f'Files in src:')\n",
    "!ls -la src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Load Modules (FIXED VERSION)\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# NOW import from src (path is fixed)\n",
    "try:\n",
    "    from src.data_collector import BinanceDataCollector\n",
    "    from src.feature_engineer import FeatureEngineer\n",
    "    from src.data_preprocessor import DataPreprocessor\n",
    "    from src.model import LSTMModel\n",
    "    from src.trainer import Trainer\n",
    "    print('✓ All modules imported successfully!')\n",
    "except ImportError as e:\n",
    "    print(f'✗ Import error: {e}')\n",
    "    print('DEBUG: sys.path:')\n",
    "    for p in sys.path[:3]:\n",
    "        print(f'  {p}')\n",
    "    raise\n",
    "\n",
    "# Load configuration\n",
    "with open('config/coins.json', 'r') as f:\n",
    "    coins_config = json.load(f)\n",
    "\n",
    "with open('config/model_params.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "coins = [coin['symbol'] for coin in coins_config['coins']]\n",
    "timeframes = ['15m', '1h']\n",
    "\n",
    "print(f'✓ Configuration loaded')\n",
    "print(f'  Total coins: {len(coins)}')\n",
    "print(f'  Timeframes: {timeframes}')\n",
    "print(f'  Total models: {len(coins) * len(timeframes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Download Data\n",
    "# ============================================================================\n",
    "\n",
    "collector = BinanceDataCollector()\n",
    "all_data = {}\n",
    "\n",
    "start_time = time.time()\n",
    "failed_coins = []\n",
    "\n",
    "# Download for first 3 coins (for speed)\n",
    "coins_to_download = coins[:3]  # BTC, ETH, SOL\n",
    "\n",
    "for i, coin in enumerate(coins_to_download):\n",
    "    coin_data = {}\n",
    "    for timeframe in timeframes:\n",
    "        try:\n",
    "            logger.info(f'[{i+1}/{len(coins_to_download)}] Downloading {coin} {timeframe}...')\n",
    "            df = collector.get_historical_klines(\n",
    "                symbol=coin,\n",
    "                interval=timeframe,\n",
    "                limit=3000\n",
    "            )\n",
    "            \n",
    "            if BinanceDataCollector.validate_data(df):\n",
    "                coin_data[timeframe] = df\n",
    "                os.makedirs('data/raw', exist_ok=True)\n",
    "                df.to_csv(f'data/raw/{coin}_{timeframe}.csv', index=False)\n",
    "                logger.info(f'✓ Saved: {coin} {timeframe}')\n",
    "            else:\n",
    "                logger.warning(f'Data validation failed for {coin} {timeframe}')\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error downloading {coin} {timeframe}: {e}')\n",
    "            failed_coins.append(f'{coin}_{timeframe}')\n",
    "    \n",
    "    if coin_data:\n",
    "        all_data[coin] = coin_data\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "logger.info(f'Data collection completed in {elapsed/60:.1f} minutes')\n",
    "logger.info(f'Downloaded: {sum([len(v) for v in all_data.values()])} datasets')\n",
    "if failed_coins:\n",
    "    logger.warning(f'Failed: {failed_coins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Train Models\n",
    "# ============================================================================\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "results = {}\n",
    "\n",
    "# Train representative models\n",
    "training_configs = [\n",
    "    ('BTCUSDT', '15m'),\n",
    "    ('ETHUSDT', '1h'),\n",
    "    ('SOLUSDT', '15m'),\n",
    "]\n",
    "\n",
    "for coin_symbol, timeframe in training_configs:\n",
    "    try:\n",
    "        logger.info(f'\\n{\"="*50}')\n",
    "        logger.info(f'Training {coin_symbol} {timeframe}')\n",
    "        logger.info(f'\"={\"*50}')\n",
    "        \n",
    "        # Load data\n",
    "        df = all_data[coin_symbol][timeframe]\n",
    "        logger.info(f'Data shape: {df.shape}')\n",
    "        \n",
    "        # Feature Engineering\n",
    "        fe = FeatureEngineer(df)\n",
    "        df_features = fe.calculate_all_indicators()\n",
    "        feature_cols = fe.get_feature_columns()\n",
    "        logger.info(f'Total features: {len(feature_cols)}')\n",
    "        \n",
    "        # Preprocessing\n",
    "        preprocessor = DataPreprocessor(df_features)\n",
    "        preprocessor.remove_nans()\n",
    "        preprocessor.select_features(feature_cols, n_components=30)\n",
    "        preprocessor.normalize_features()\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = preprocessor.create_sequences()\n",
    "        data_split = preprocessor.split_train_val_test(X, y)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        X_train = torch.FloatTensor(data_split['X_train']).to(device)\n",
    "        y_train = torch.FloatTensor(data_split['y_train']).to(device)\n",
    "        X_val = torch.FloatTensor(data_split['X_val']).to(device)\n",
    "        y_val = torch.FloatTensor(data_split['y_val']).to(device)\n",
    "        \n",
    "        from torch.utils.data import DataLoader, TensorDataset\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # Build model\n",
    "        model = LSTMModel.create_model(model_config, device=device)\n",
    "        logger.info(f'Model parameters: {model.count_parameters():,}')\n",
    "        \n",
    "        # Train\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        save_path = f'models/{coin_symbol}_{timeframe}.pt'\n",
    "        \n",
    "        trainer = Trainer(model, device=device)\n",
    "        history = trainer.train(\n",
    "            train_loader, val_loader,\n",
    "            epochs=50,\n",
    "            learning_rate=0.001,\n",
    "            patience=15,\n",
    "            save_path=save_path\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        results[f'{coin_symbol}_{timeframe}'] = {\n",
    "            'best_val_loss': float(history['best_val_loss']),\n",
    "            'best_epoch': history['best_epoch'],\n",
    "            'total_epochs': history['total_epochs']\n",
    "        }\n",
    "        \n",
    "        logger.info(f'✓ Completed: {coin_symbol} {timeframe}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f'✗ Error training {coin_symbol} {timeframe}: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Save results\n",
    "with open('results/training_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "logger.info(f'\\n{\"="*50}')\n",
    "logger.info(f'Training Summary')\n",
    "logger.info(f'\"={\"*50}')\n",
    "for key, val in results.items():\n",
    "    logger.info(f'{key}: Loss={val[\"best_val_loss\"]:.6f}, Epoch={val[\"best_epoch\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: (Optional) Upload to Hugging Face\n",
    "# ============================================================================\n",
    "\n",
    "# Note: Requires HF_TOKEN environment variable\n",
    "# Set it with: !huggingface-cli login\n",
    "\n",
    "logger.info('To upload models to Hugging Face:')\n",
    "logger.info('1. Run: !huggingface-cli login')\n",
    "logger.info('2. Paste your token')\n",
    "logger.info('3. Run: python scripts/hf_upload.py')\n",
    "logger.info('')\n",
    "logger.info('Or manually upload:')\n",
    "logger.info('from huggingface_hub import upload_file')\n",
    "logger.info('upload_file(path=\"models/BTCUSDT_15m.pt\", repo_id=\"your_username/cpb\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Results Summary\n",
    "# ============================================================================\n",
    "\n",
    "logger.info('\\n' + '='*70)\n",
    "logger.info('TRAINING COMPLETE!')\n",
    "logger.info('='*70)\n",
    "\n",
    "if results:\n",
    "    logger.info(f'\\nModels trained: {len(results)}')\n",
    "    if results:\n",
    "        best_model = min(results.items(), key=lambda x: x[1]['best_val_loss'])\n",
    "        logger.info(f'Best model: {best_model[0]}')\n",
    "        logger.info(f'  Validation Loss: {best_model[1][\"best_val_loss\"]:.6f}')\n",
    "        logger.info(f'  Best Epoch: {best_model[1][\"best_epoch\"]}/{best_model[1][\"total_epochs\"]}')\n",
    "\n",
    "logger.info('\\nFiles saved:')\n",
    "logger.info('  ✓ models/*.pt - Model weights')\n",
    "logger.info('  ✓ data/raw/*.csv - Downloaded data')\n",
    "logger.info('  ✓ results/training_results.json - Training metrics')\n",
    "\n",
    "logger.info('\\nNext steps:')\n",
    "logger.info('  1. Download models from /tmp/cpbv2/models/')\n",
    "logger.info('  2. (Optional) Upload to Hugging Face')\n",
    "logger.info('  3. Use for inference or further training')\n",
    "\n",
    "logger.info('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
