{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPB v2: All-in-One Colab Training\n",
    "\n",
    "**一体化训练系统 - 所有代码集成在 Colab 中**\n",
    "\n",
    "优点：\n",
    "- 无需每次重复设置环境\n",
    "- 可直接在 Colab 中编辑代码\n",
    "- 环境一次配置，永久保留\n",
    "- 快速迭代开发\n",
    "\n",
    "执行步骤：\n",
    "1. 运行 Cell 1: 环境设置 (仅需一次)\n",
    "2. 运行 Cell 2-4: 加载内置模块\n",
    "3. 运行 Cell 5+: 执行训练\n",
    "4. 修改参数后，只需重新运行相关 Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP CELL (仅需运行一次)\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 安装依赖 (只在第一次运行)\n",
    "print('Installing dependencies...')\n",
    "!pip install -q torch pandas numpy scikit-learn requests ta-lib pandas-ta huggingface-hub tqdm 2>/dev/null\n",
    "print('✓ Dependencies installed')\n",
    "\n",
    "# 检查 GPU\n",
    "import torch\n",
    "print(f'\\nGPU Available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 1: Data Collector (内置代码)\n",
    "# 可以直接在这里编辑！\n",
    "# ============================================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BinanceDataCollector:\n",
    "    \"\"\"Binance API 数据采集器\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.binance.com/api/v3\"\n",
    "    MAX_CANDLES = 1000\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def get_klines(self, symbol, interval=\"15m\", limit=3000):\n",
    "        \"\"\"下载 K 线数据\"\"\"\n",
    "        print(f'Downloading {symbol} {interval}...')\n",
    "        \n",
    "        all_klines = []\n",
    "        end_time = int(datetime.utcnow().timestamp() * 1000)\n",
    "        start_time = int((datetime.utcnow() - timedelta(days=90)).timestamp() * 1000)\n",
    "        current_start = start_time\n",
    "        \n",
    "        retry_count = 0\n",
    "        \n",
    "        while current_start < end_time and len(all_klines) < limit:\n",
    "            try:\n",
    "                params = {\n",
    "                    \"symbol\": symbol,\n",
    "                    \"interval\": interval,\n",
    "                    \"startTime\": current_start,\n",
    "                    \"limit\": min(self.MAX_CANDLES, limit - len(all_klines))\n",
    "                }\n",
    "                \n",
    "                response = self.session.get(\n",
    "                    f\"{self.BASE_URL}/klines\",\n",
    "                    params=params,\n",
    "                    timeout=10\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                klines = response.json()\n",
    "                if not klines:\n",
    "                    break\n",
    "                \n",
    "                all_klines.extend(klines)\n",
    "                current_start = int(klines[-1][0]) + 1\n",
    "                retry_count = 0\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count >= 3:\n",
    "                    print(f'Error: {e}')\n",
    "                    break\n",
    "                time.sleep(2 ** retry_count)\n",
    "        \n",
    "        # 转换为 DataFrame\n",
    "        if not all_klines:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(all_klines, columns=[\n",
    "            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "            'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'\n",
    "        ])\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "        \n",
    "        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].drop_duplicates().sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        print(f'✓ Downloaded {len(df)} candles')\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate(df):\n",
    "        if len(df) < 100:\n",
    "            return False\n",
    "        if df[['open', 'high', 'low', 'close', 'volume']].isnull().any().any():\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "print('✓ BinanceDataCollector 已加载')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 2: Feature Engineer (内置代码)\n",
    "# 可以直接在这里编辑！\n",
    "# ============================================================================\n",
    "\n",
    "class FeatureEngineer:\n",
    "    \"\"\"技术指标计算\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "    \n",
    "    def calculate_all(self):\n",
    "        df = self.df\n",
    "        \n",
    "        # 移动平均\n",
    "        for period in [10, 20, 50, 100, 200]:\n",
    "            df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()\n",
    "        \n",
    "        # RSI\n",
    "        for period in [14, 21]:\n",
    "            delta = df['close'].diff()\n",
    "            gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "            loss = -delta.where(delta < 0, 0).rolling(period).mean()\n",
    "            rs = gain / loss\n",
    "            df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # MACD\n",
    "        ema12 = df['close'].ewm(span=12).mean()\n",
    "        ema26 = df['close'].ewm(span=26).mean()\n",
    "        df['macd'] = ema12 - ema26\n",
    "        df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "        df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        sma20 = df['close'].rolling(20).mean()\n",
    "        std20 = df['close'].rolling(20).std()\n",
    "        df['bb_upper'] = sma20 + (std20 * 2)\n",
    "        df['bb_lower'] = sma20 - (std20 * 2)\n",
    "        df['bb_width'] = df['bb_upper'] - df['bb_lower']\n",
    "        \n",
    "        # ATR\n",
    "        tr = pd.concat([\n",
    "            df['high'] - df['low'],\n",
    "            (df['high'] - df['close'].shift()).abs(),\n",
    "            (df['low'] - df['close'].shift()).abs()\n",
    "        ], axis=1).max(axis=1)\n",
    "        df['atr_14'] = tr.rolling(14).mean()\n",
    "        \n",
    "        # OBV\n",
    "        df['obv'] = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()\n",
    "        \n",
    "        # 价格变化\n",
    "        df['price_change'] = df['close'].pct_change() * 100\n",
    "        df['volume_change'] = df['volume'].pct_change() * 100\n",
    "        \n",
    "        self.df = df.fillna(0)\n",
    "        return self.df\n",
    "    \n",
    "    def get_features(self):\n",
    "        exclude = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "        return [col for col in self.df.columns if col not in exclude]\n",
    "\n",
    "print('✓ FeatureEngineer 已加载')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 3: Preprocessing (内置代码)\n",
    "# 可以直接在这里编辑！\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, df, lookback=60):\n",
    "        self.df = df.copy()\n",
    "        self.lookback = lookback\n",
    "        self.scaler = MinMaxScaler((0, 1))\n",
    "        self.pca = None\n",
    "    \n",
    "    def prepare(self, feature_cols, n_components=30):\n",
    "        # 移除 NaN\n",
    "        self.df = self.df.dropna()\n",
    "        \n",
    "        # 特征选择\n",
    "        feature_data = self.df[feature_cols].copy()\n",
    "        \n",
    "        if len(feature_cols) > n_components:\n",
    "            self.pca = PCA(n_components=n_components)\n",
    "            feature_data = self.pca.fit_transform(feature_data)\n",
    "            feature_cols = [f'pc_{i}' for i in range(n_components)]\n",
    "            feature_data = pd.DataFrame(feature_data, columns=feature_cols, index=self.df.index)\n",
    "        \n",
    "        # 归一化\n",
    "        feature_data = self.scaler.fit_transform(feature_data)\n",
    "        \n",
    "        self.features = feature_data\n",
    "        self.feature_cols = feature_cols\n",
    "        \n",
    "        return feature_data, feature_cols\n",
    "    \n",
    "    def create_sequences(self):\n",
    "        X, y = [], []\n",
    "        data = self.features\n",
    "        \n",
    "        for i in range(self.lookback, len(data)):\n",
    "            X.append(data[i - self.lookback:i])\n",
    "            y.append(data[i, 0])\n",
    "        \n",
    "        return np.array(X), np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    def split_data(self, X, y, train_ratio=0.7):\n",
    "        n = len(X)\n",
    "        train_idx = int(n * train_ratio)\n",
    "        val_idx = int(n * (train_ratio + 0.15))\n",
    "        \n",
    "        return {\n",
    "            'X_train': X[:train_idx], 'y_train': y[:train_idx],\n",
    "            'X_val': X[train_idx:val_idx], 'y_val': y[train_idx:val_idx],\n",
    "            'X_test': X[val_idx:], 'y_test': y[val_idx:]\n",
    "        }\n",
    "\n",
    "print('✓ DataPreprocessor 已加载')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 4: LSTM Model (内置代码)\n",
    "# 可以直接在这里编辑！\n",
    "# ============================================================================\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=30, lstm_units=[96, 64], dense_units=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, lstm_units[0], batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(lstm_units[0] * 2, lstm_units[1], batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        \n",
    "        lstm_output = lstm_units[1] * 2\n",
    "        self.dense1 = nn.Linear(lstm_output, dense_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.Linear(dense_units, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm1_out, _ = self.lstm1(x)\n",
    "        lstm2_out, _ = self.lstm2(lstm1_out)\n",
    "        last_out = lstm2_out[:, -1, :]\n",
    "        \n",
    "        dense_out = self.dense1(last_out)\n",
    "        dense_out = self.relu(dense_out)\n",
    "        dense_out = self.dropout(dense_out)\n",
    "        output = self.dense2(dense_out)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def count_params(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32, lr=0.001):\n",
    "        X_train_t = torch.FloatTensor(X_train).to(self.device)\n",
    "        y_train_t = torch.FloatTensor(y_train).to(self.device)\n",
    "        X_val_t = torch.FloatTensor(X_val).to(self.device)\n",
    "        y_val_t = torch.FloatTensor(y_val).to(self.device)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_val_t, y_val_t), batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        patience = 15\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # Val\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    output = self.model(X_batch)\n",
    "                    loss = criterion(output, y_batch)\n",
    "                    val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}: Train={train_loss:.6f}, Val={val_loss:.6f}')\n",
    "            \n",
    "            if val_loss < best_val_loss - 0.0001:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_weights = self.model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f'Early stopping at epoch {epoch+1}')\n",
    "                    self.model.load_state_dict(best_weights)\n",
    "                    break\n",
    "        \n",
    "        return {'best_val_loss': float(best_val_loss), 'epochs': epoch+1}\n",
    "\n",
    "print('✓ LSTMModel 和 Trainer 已加载')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "\n",
    "# 配置\n",
    "CONFIG = {\n",
    "    'coins': ['BTCUSDT', 'ETHUSDT', 'SOLUSDT'],  # 修改币种列表\n",
    "    'timeframes': ['15m', '1h'],\n",
    "    'epochs': 50,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'lookback': 60,\n",
    "    'n_features': 30\n",
    "}\n",
    "\n",
    "print(f'Config: {json.dumps(CONFIG, indent=2)}')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Download Data\n",
    "# ============================================================================\n",
    "\n",
    "collector = BinanceDataCollector()\n",
    "all_data = {}\n",
    "\n",
    "print('\\n=== DATA DOWNLOAD ===')\n",
    "for coin in CONFIG['coins']:\n",
    "    coin_data = {}\n",
    "    for timeframe in CONFIG['timeframes']:\n",
    "        try:\n",
    "            df = collector.get_klines(coin, timeframe, limit=3000)\n",
    "            if BinanceDataCollector.validate(df):\n",
    "                coin_data[timeframe] = df\n",
    "            else:\n",
    "                print(f'  ✗ {coin} {timeframe} validation failed')\n",
    "        except Exception as e:\n",
    "            print(f'  ✗ {coin} {timeframe}: {e}')\n",
    "    \n",
    "    if coin_data:\n",
    "        all_data[coin] = coin_data\n",
    "        print(f'✓ {coin}: {len(coin_data)} timeframes')\n",
    "\n",
    "print(f'\\nTotal: {sum([len(v) for v in all_data.values()])} datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Train Models\n",
    "# ============================================================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "print('\\n=== TRAINING ===')\n",
    "\n",
    "for coin in all_data:\n",
    "    for timeframe in all_data[coin]:\n",
    "        print(f'\\n--- {coin} {timeframe} ---')\n",
    "        \n",
    "        try:\n",
    "            # 数据准备\n",
    "            df = all_data[coin][timeframe]\n",
    "            \n",
    "            # 特征工程\n",
    "            fe = FeatureEngineer(df)\n",
    "            df_features = fe.calculate_all()\n",
    "            feature_cols = fe.get_features()\n",
    "            \n",
    "            # 预处理\n",
    "            prep = DataPreprocessor(df_features, lookback=CONFIG['lookback'])\n",
    "            features, feature_cols = prep.prepare(feature_cols, CONFIG['n_features'])\n",
    "            X, y = prep.create_sequences()\n",
    "            data = prep.split_data(X, y)\n",
    "            \n",
    "            # 构建模型\n",
    "            model = LSTMModel(input_size=features.shape[-1])\n",
    "            print(f'Model params: {model.count_params():,}')\n",
    "            \n",
    "            # 训练\n",
    "            trainer = Trainer(model, device=device)\n",
    "            history = trainer.train(\n",
    "                data['X_train'], data['y_train'],\n",
    "                data['X_val'], data['y_val'],\n",
    "                epochs=CONFIG['epochs'],\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                lr=CONFIG['learning_rate']\n",
    "            )\n",
    "            \n",
    "            results[f'{coin}_{timeframe}'] = history\n",
    "            print(f'✓ Best Val Loss: {history[\"best_val_loss\"]:.6f}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'✗ Error: {e}')\n",
    "\n",
    "print(f'\\n=== SUMMARY ===')\n",
    "print(f'Trained: {len(results)} models')\n",
    "for key, val in results.items():\n",
    "    print(f'  {key}: loss={val[\"best_val_loss\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编辑代码指南\n",
    "\n",
    "### 如何在 Colab 中修改代码\n",
    "\n",
    "无需重新设置环境，直接编辑和运行：\n",
    "\n",
    "#### 1. 修改配置 (Cell 5)\n",
    "```python\n",
    "CONFIG = {\n",
    "    'coins': ['BTCUSDT', 'ETHUSDT'],  # 改这里\n",
    "    'epochs': 100,  # 改这里\n",
    "    'batch_size': 16  # 改这里\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2. 修改模块代码\n",
    "- Cell 2: 编辑 `BinanceDataCollector`\n",
    "- Cell 3: 编辑 `FeatureEngineer` 添加更多指标\n",
    "- Cell 4: 编辑 `LSTMModel` 改变模型架构\n",
    "\n",
    "#### 3. 修改后运行\n",
    "1. 修改对应 Cell\n",
    "2. **Ctrl+Enter** 运行该 Cell\n",
    "3. 如果修改了 CONFIG，运行 Cell 5-7\n",
    "4. 无需重新运行 Cell 1 (仅需一次)\n",
    "\n",
    "### 环境会一直保留！\n",
    "\n",
    "- 首次运行 Cell 1 安装依赖\n",
    "- 后续只需修改和运行相关 Cell\n",
    "- GPU 会话保留 12 小时\n",
    "- 所有模块会一直存在于内存中\n",
    "\n",
    "### 快速迭代工作流\n",
    "\n",
    "```\n",
    "第一次运行:           后续迭代:\n",
    "1. Cell 1 (setup)     1. 修改对应 Cell\n",
    "2. Cell 2-4 (load)    2. Ctrl+Enter 运行\n",
    "3. Cell 5-7 (train)   3. 查看结果\n",
    "                      4. 重复\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
